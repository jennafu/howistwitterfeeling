{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Reduced Dataset (With Numerical Features)\n",
    "\n",
    "With the reduced dataset, there are four models I want to attempt to train my model on:\n",
    "- LogisticRegression\n",
    "- LinearSVC\n",
    "- DecisionTreeClassifier\n",
    "- KNeighborsClassifier\n",
    "\n",
    "These are the steps I will be taking in this notebook:\n",
    "1. Compare the baseline models for each classifiers but with their respective best performing scalers.\n",
    "2. Out of the four baseline models, pick the best two and conduct hyperparameter tuning on them.\n",
    "3. Pick the best performing classifier and its respective hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Classifiers used\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the reduced datasets\n",
    "X_train = pd.read_csv('data/reduced_model/X_train_reduced.csv',index_col=0)\n",
    "X_test = pd.read_csv('data/reduced_model/X_test_reduced.csv',index_col=0)\n",
    "y_train = pd.read_csv('data/reduced_model/y_train.csv',index_col=0)\n",
    "y_test = pd.read_csv('data/reduced_model/y_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_weekday</th>\n",
       "      <th>hashtag_counts</th>\n",
       "      <th>user_counts</th>\n",
       "      <th>url_counts</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>...</th>\n",
       "      <th>z</th>\n",
       "      <th>za</th>\n",
       "      <th>zac</th>\n",
       "      <th>zach</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 5989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_hour  date_day  date_month  date_weekday  hashtag_counts  \\\n",
       "0              1        15           6             1               0   \n",
       "1             18         6           6             6               0   \n",
       "2             13        20           6             6               0   \n",
       "3             18        15           6             1               0   \n",
       "4              2        15           6             1               0   \n",
       "...          ...       ...         ...           ...             ...   \n",
       "79995         15        15           6             1               0   \n",
       "79996         14        18           4             6               0   \n",
       "79997          2        14           5             4               0   \n",
       "79998          4         1           6             1               0   \n",
       "79999          1         4           5             1               0   \n",
       "\n",
       "       user_counts  url_counts   aa  aaa  aaaa  ...    z   za  zac  zach  \\\n",
       "0                1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "1                2           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "2                1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "3                0           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "4                1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "...            ...         ...  ...  ...   ...  ...  ...  ...  ...   ...   \n",
       "79995            1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "79996            0           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "79997            1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "79998            1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "79999            1           0  0.0  0.0   0.0  ...  0.0  0.0  0.0   0.0   \n",
       "\n",
       "       zealand  zero  zombie  zomg  zone  zoo  \n",
       "0          0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "1          0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "2          0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "3          0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "4          0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "...        ...   ...     ...   ...   ...  ...  \n",
       "79995      0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "79996      0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "79997      0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "79998      0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "79999      0.0   0.0     0.0   0.0   0.0  0.0  \n",
       "\n",
       "[80000 rows x 5989 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be comparing the baseline models for each classifiers but with their respective best performing scalers. Given that my laptop will have more computing power, I will definitely implement a GridSearchCV to find the best combinations of scalers, classifiers and their hyperparameter. However, given the current restriction, I will be identifying the best choices in each steps manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "0.757425\n",
      "0.7497\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "0.757425\n",
      "0.7497\n",
      "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "0.757425\n",
      "0.7497\n"
     ]
    }
   ],
   "source": [
    "# Scale the train and test sets, with three types of scalers\n",
    "for scaler in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "    \n",
    "    # Fit the data to scaler\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    # Instantiate and fit to the train set\n",
    "    Logistic = LogisticRegression()\n",
    "    \n",
    "    # Fit the data\n",
    "    Logistic.fit(X_train,y_train)\n",
    "    \n",
    "    # Score the model\n",
    "    print(scaler)\n",
    "    print(Logistic.score(X_train,y_train))\n",
    "    print(Logistic.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Cross validation training accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic w/ robust scaler</th>\n",
       "      <td>0.757425</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.756037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Training accuracy  Test accuracy  \\\n",
       "logistic w/ robust scaler           0.757425         0.7497   \n",
       "\n",
       "                           Cross validation training accuracy  \n",
       "logistic w/ robust scaler                            0.756037  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to report model accuracy, including train, test and cross validation train accuracy\n",
    "accuracy_data = {'Training accuracy':  [Logistic.score(X_train,y_train)],\n",
    "        'Test accuracy': [Logistic.score(X_test,y_test)],\n",
    "        'Cross validation training accuracy': [np.mean(cross_val_score(Logistic,X_train,y_train))]}\n",
    "\n",
    "accuracy = pd.DataFrame(accuracy_data, \n",
    "                        columns = ['Training accuracy','Test accuracy',\n",
    "                                   'Cross validation training accuracy'],\n",
    "                        index = ['logistic w/ robust scaler']\n",
    "                       )\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "0.790775\n",
      "0.7569\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "0.7489625\n",
      "0.71975\n",
      "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "0.80845\n",
      "0.76785\n"
     ]
    }
   ],
   "source": [
    "# Scale the train and test sets, with three types of scalers\n",
    "for scaler in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "    \n",
    "    # Fit the data to scaler\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    # Instantiate and fit to the train set\n",
    "    SVC = LinearSVC()\n",
    "    \n",
    "    # Fit the data\n",
    "    SVC.fit(X_train,y_train)\n",
    "    \n",
    "    # Score the model\n",
    "    print(scaler)\n",
    "    print(SVC.score(X_train,y_train))\n",
    "    print(SVC.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the RobustScaler is the best scaler to use along the LinearSVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Cross validation training accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic w/ robust scaler</th>\n",
       "      <td>0.757425</td>\n",
       "      <td>0.74970</td>\n",
       "      <td>0.756037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC w/ robust scaler</th>\n",
       "      <td>0.808450</td>\n",
       "      <td>0.76785</td>\n",
       "      <td>0.759550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Training accuracy  Test accuracy  \\\n",
       "logistic w/ robust scaler           0.757425        0.74970   \n",
       "SVC w/ robust scaler                0.808450        0.76785   \n",
       "\n",
       "                           Cross validation training accuracy  \n",
       "logistic w/ robust scaler                            0.756037  \n",
       "SVC w/ robust scaler                                 0.759550  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the accuracy scores of this model to our accuracy score dataframe `accuracy`\n",
    "accuracy_data = {'Training accuracy':  [SVC.score(X_train,y_train)],\n",
    "        'Test accuracy': [SVC.score(X_test,y_test)],\n",
    "        'Cross validation training accuracy': [np.mean(cross_val_score(SVC,X_train,y_train))]\n",
    "        }\n",
    "\n",
    "new_accuracy = pd.DataFrame(accuracy_data, index = [\"SVC w/ robust scaler\"])\n",
    "accuracy = pd.concat([accuracy,new_accuracy])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "0.9973625\n",
      "0.72795\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "0.9973625\n",
      "0.725\n",
      "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "0.9973625\n",
      "0.72675\n"
     ]
    }
   ],
   "source": [
    "# Scale the train and test sets, with three types of scalers\n",
    "for scaler in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "    \n",
    "    # Fit the data to scaler\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    # Instantiate and fit to the train set\n",
    "    DT = DecisionTreeClassifier()\n",
    "    \n",
    "    # Fit the data\n",
    "    DT.fit(X_train,y_train)\n",
    "    \n",
    "    # Score the model\n",
    "    print(scaler)\n",
    "    print(DT.score(X_train,y_train))\n",
    "    print(DT.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Cross validation training accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic w/ robust scaler</th>\n",
       "      <td>0.757425</td>\n",
       "      <td>0.74970</td>\n",
       "      <td>0.756037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC w/ robust scaler</th>\n",
       "      <td>0.808450</td>\n",
       "      <td>0.76785</td>\n",
       "      <td>0.759550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT w/ robust scaler</th>\n",
       "      <td>0.997363</td>\n",
       "      <td>0.72675</td>\n",
       "      <td>0.727087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Training accuracy  Test accuracy  \\\n",
       "logistic w/ robust scaler           0.757425        0.74970   \n",
       "SVC w/ robust scaler                0.808450        0.76785   \n",
       "DT w/ robust scaler                 0.997363        0.72675   \n",
       "\n",
       "                           Cross validation training accuracy  \n",
       "logistic w/ robust scaler                            0.756037  \n",
       "SVC w/ robust scaler                                 0.759550  \n",
       "DT w/ robust scaler                                  0.727087  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the accuracy scores of this model to our accuracy score dataframe `accuracy`\n",
    "accuracy_data = {'Training accuracy':  [DT.score(X_train,y_train)],\n",
    "        'Test accuracy': [DT.score(X_test,y_test)],\n",
    "        'Cross validation training accuracy': [np.mean(cross_val_score(DT,X_train,y_train))]\n",
    "        }\n",
    "\n",
    "new_accuracy = pd.DataFrame(accuracy_data, index = [\"DT w/ robust scaler\"])\n",
    "accuracy = pd.concat([accuracy,new_accuracy])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Cross validation training accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic w/ robust scaler</th>\n",
       "      <td>0.757425</td>\n",
       "      <td>0.74970</td>\n",
       "      <td>0.756037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC w/ robust scaler</th>\n",
       "      <td>0.808450</td>\n",
       "      <td>0.76785</td>\n",
       "      <td>0.759550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT w/ robust scaler</th>\n",
       "      <td>0.997363</td>\n",
       "      <td>0.72675</td>\n",
       "      <td>0.727087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Training accuracy  Test accuracy  \\\n",
       "logistic w/ robust scaler           0.757425        0.74970   \n",
       "SVC w/ robust scaler                0.808450        0.76785   \n",
       "DT w/ robust scaler                 0.997363        0.72675   \n",
       "\n",
       "                           Cross validation training accuracy  \n",
       "logistic w/ robust scaler                            0.756037  \n",
       "SVC w/ robust scaler                                 0.759550  \n",
       "DT w/ robust scaler                                  0.727087  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "0.79095\n",
      "0.6745\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "0.79095\n",
      "0.6745\n",
      "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "0.79095\n",
      "0.6745\n"
     ]
    }
   ],
   "source": [
    "# Scale the train and test sets, with three types of scalers\n",
    "for scaler in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "    \n",
    "    # Fit the data to scaler\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    # Instantiate and fit to the train set\n",
    "    KNN = KNeighborsClassifier()\n",
    "    \n",
    "    # Fit the data\n",
    "    KNN.fit(X_train,y_train)\n",
    "    \n",
    "    # Score the model\n",
    "    print(scaler)\n",
    "    print(KNN.score(X_train,y_train))\n",
    "    print(KNN.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter Tuning for SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hyperparameter tuning, I will be further splitting my train data into train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train1 = X_train1.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_train1 = y_train1.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression\n",
    "Two hyperparamters I will be looking into for LogisticRegression, are its penalty and C. Tuning penalty allows us to compare two regularization techniques L1(Lasso Regression) and L2(Ridge Regression), which introduces different penalty term and works along with the regularization parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 0.0001\n",
      "l1 0.001\n",
      "l1 0.01\n",
      "l1 0.1\n",
      "l1 1\n",
      "l1 10\n",
      "l2 0.0001\n",
      "l2 0.001\n",
      "l2 0.01\n",
      "l2 0.1\n",
      "l2 1\n",
      "l2 10\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit the data to scaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit_transform(X_train1)\n",
    "scaler.transform(X_val)\n",
    "\n",
    "log_comb = []\n",
    "log_train = []\n",
    "log_test = []\n",
    "for i in ['l1','l2']:\n",
    "    for j in [0.0001,0.001,0.01,0.1,1,10]:\n",
    "        clf = LogisticRegression(penalty = i ,C = j,solver ='saga')\n",
    "        clf = clf.fit(X_train1, y_train1)\n",
    "        # Score the model\n",
    "        print(i,j)\n",
    "        log_comb.append([i,j])\n",
    "        log_train.append(clf.score(X_train1,y_train1))   \n",
    "        log_test.append(clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,len(log_comb)),log_train,label='train')\n",
    "plt.plot(range(0,len(log_comb)),log_test,label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the best combination of hyperparameters would be when penalty = l1 and C = 10. Now let's apply them to our train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826625\n",
      "0.7694\n"
     ]
    }
   ],
   "source": [
    "# Fit the data to scaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the model\n",
    "clf = LogisticRegression(penalty = 'l1',C = 10,solver='saga')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC\n",
    "Two hyperparamters I will be looking into for LinearSVC, are its class_weight and C. The reason why class_weight is choosen, is because in the baseline model, I have seen a relatively high false negative rate and low recall rate, leading to less tweets being classified as positive. I have also chosen to tune the regularization parameter C for structural risk minimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Fit the data to scaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit_transform(X_train1)\n",
    "scaler.transform(X_val)\n",
    "\n",
    "svc_comb = []\n",
    "svc_counter = []\n",
    "svc_score = []\n",
    "for i in [0.0001,0.001,0.01,0.1,1,10]:\n",
    "    for j in range(2,6):\n",
    "        clf = LinearSVC(C = i ,class_weight={-1: 1, 1: j})\n",
    "        clf = clf.fit(X_train1, y_train1)\n",
    "        # Score the model\n",
    "        svc_comb.append([i,j])\n",
    "        svc_counter.append(Counter(clf.predict(X_val)))\n",
    "        svc_score.append(clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Counter</th>\n",
       "      <th>Training accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0001, 2]</td>\n",
       "      <td>{1: 15638, -1: 362}</td>\n",
       "      <td>0.511938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0001, 3]</td>\n",
       "      <td>{1: 16000}</td>\n",
       "      <td>0.495937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0001, 4]</td>\n",
       "      <td>{1: 16000}</td>\n",
       "      <td>0.495937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0001, 5]</td>\n",
       "      <td>{1: 16000}</td>\n",
       "      <td>0.495937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.001, 2]</td>\n",
       "      <td>{-1: 2368, 1: 13632}</td>\n",
       "      <td>0.618437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.001, 3]</td>\n",
       "      <td>{1: 15410, -1: 590}</td>\n",
       "      <td>0.531312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.001, 4]</td>\n",
       "      <td>{1: 15803, -1: 197}</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.001, 5]</td>\n",
       "      <td>{1: 15903, -1: 97}</td>\n",
       "      <td>0.501875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.01, 2]</td>\n",
       "      <td>{-1: 4665, 1: 11335}</td>\n",
       "      <td>0.723250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.01, 3]</td>\n",
       "      <td>{-1: 3151, 1: 12849}</td>\n",
       "      <td>0.665375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.01, 4]</td>\n",
       "      <td>{-1: 2336, 1: 13664}</td>\n",
       "      <td>0.627062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.01, 5]</td>\n",
       "      <td>{-1: 1803, 1: 14197}</td>\n",
       "      <td>0.599750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.1, 2]</td>\n",
       "      <td>{-1: 5658, 1: 10342}</td>\n",
       "      <td>0.753437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.1, 3]</td>\n",
       "      <td>{-1: 4708, 1: 11292}</td>\n",
       "      <td>0.726812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.1, 4]</td>\n",
       "      <td>{-1: 4267, 1: 11733}</td>\n",
       "      <td>0.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.1, 5]</td>\n",
       "      <td>{-1: 2897, 1: 13103}</td>\n",
       "      <td>0.653500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{-1: 4647, 1: 11353}</td>\n",
       "      <td>0.710250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>{-1: 7422, 1: 8578}</td>\n",
       "      <td>0.756437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>{-1: 9929, 1: 6071}</td>\n",
       "      <td>0.721875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 5]</td>\n",
       "      <td>{-1: 9192, 1: 6808}</td>\n",
       "      <td>0.719562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[10, 2]</td>\n",
       "      <td>{-1: 6260, 1: 9740}</td>\n",
       "      <td>0.712688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[10, 3]</td>\n",
       "      <td>{-1: 1879, 1: 14121}</td>\n",
       "      <td>0.595375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[10, 4]</td>\n",
       "      <td>{-1: 4574, 1: 11426}</td>\n",
       "      <td>0.678687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[10, 5]</td>\n",
       "      <td>{-1: 8144, 1: 7856}</td>\n",
       "      <td>0.738062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Combination               Counter  Training accuracy\n",
       "0   [0.0001, 2]   {1: 15638, -1: 362}           0.511938\n",
       "1   [0.0001, 3]            {1: 16000}           0.495937\n",
       "2   [0.0001, 4]            {1: 16000}           0.495937\n",
       "3   [0.0001, 5]            {1: 16000}           0.495937\n",
       "4    [0.001, 2]  {-1: 2368, 1: 13632}           0.618437\n",
       "5    [0.001, 3]   {1: 15410, -1: 590}           0.531312\n",
       "6    [0.001, 4]   {1: 15803, -1: 197}           0.508000\n",
       "7    [0.001, 5]    {1: 15903, -1: 97}           0.501875\n",
       "8     [0.01, 2]  {-1: 4665, 1: 11335}           0.723250\n",
       "9     [0.01, 3]  {-1: 3151, 1: 12849}           0.665375\n",
       "10    [0.01, 4]  {-1: 2336, 1: 13664}           0.627062\n",
       "11    [0.01, 5]  {-1: 1803, 1: 14197}           0.599750\n",
       "12     [0.1, 2]  {-1: 5658, 1: 10342}           0.753437\n",
       "13     [0.1, 3]  {-1: 4708, 1: 11292}           0.726812\n",
       "14     [0.1, 4]  {-1: 4267, 1: 11733}           0.712000\n",
       "15     [0.1, 5]  {-1: 2897, 1: 13103}           0.653500\n",
       "16       [1, 2]  {-1: 4647, 1: 11353}           0.710250\n",
       "17       [1, 3]   {-1: 7422, 1: 8578}           0.756437\n",
       "18       [1, 4]   {-1: 9929, 1: 6071}           0.721875\n",
       "19       [1, 5]   {-1: 9192, 1: 6808}           0.719562\n",
       "20      [10, 2]   {-1: 6260, 1: 9740}           0.712688\n",
       "21      [10, 3]  {-1: 1879, 1: 14121}           0.595375\n",
       "22      [10, 4]  {-1: 4574, 1: 11426}           0.678687\n",
       "23      [10, 5]   {-1: 8144, 1: 7856}           0.738062"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_parameters = {'Combination':  svc_comb,\n",
    "        'Counter': svc_counter,\n",
    "        'Training accuracy': svc_score\n",
    "        }\n",
    "\n",
    "svc_parameters = pd.DataFrame(svc_parameters)\n",
    "svc_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the best combination of hyperparameters might be when C=1(default) and class_weight={-1: 1, 1: 4}, in terms of model accuracy and the classification balance. Now let's apply it to our train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781875\n",
      "0.7455\n"
     ]
    }
   ],
   "source": [
    "# Fit the data to scaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the model\n",
    "clf = LinearSVC(C = 1 ,class_weight={-1: 1, 1: 5})\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further investigate whether or not the model was able to resolve the issue with low recall rate, I will be assessing it with the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6590, 3428],\n",
       "       [1662, 8320]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Performing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that out of the two classifiers after hyperparameter tunings, the best performing model is the SVC model with `class_weight = {-1: 1, 1: 5}` and `C = 1`. Hence, we will be using this model to derive sentiments from the real-time Twitter data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'pickle/svc_reduced_model.sav'\n",
    "# save the model to disk\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model with Reduced Dataset (Without Numerical Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
